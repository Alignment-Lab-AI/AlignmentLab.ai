<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Alignment Lab AI</title><meta name="description" content="Alignment Lab AI, Utility, Transparency, Accessiblity"/><link rel="icon" href="/favicon.ico"/><meta name="next-head-count" content="5"/><link rel="preload" href="/_next/static/media/414fe043d41639e8.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font=""/><link rel="preload" href="/_next/static/css/1dc8bd6a3d16c9c4.css" as="style" crossorigin=""/><link rel="stylesheet" href="/_next/static/css/1dc8bd6a3d16c9c4.css" crossorigin="" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" crossorigin="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8fa1640cc84ba8fe.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/framework-5429a50ba5373c56.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/main-359cf9259ad67a06.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/_app-110ad366a407f7ce.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/29-59641967bdf86302.js" defer="" crossorigin=""></script><script src="/_next/static/chunks/pages/news-c051e900a4311086.js" defer="" crossorigin=""></script><script src="/_next/static/u4rPOVbKVnVu4tFdyUjxe/_buildManifest.js" defer="" crossorigin=""></script><script src="/_next/static/u4rPOVbKVnVu4tFdyUjxe/_ssgManifest.js" defer="" crossorigin=""></script></head><body><div id="__next"><div class="__className_1e81eb flex flex-col h-screen justify-between bg-slate-50 dark:bg-slate-900 text-slate-900 dark:text-slate-200"><header class="border-b"><div class="flex justify-between py-4 items-center mx-2 md:mx-4"><a href="/"><div class="flex items-center gap-0 hover:text-teal-400 transition duration-300"><svg aria-hidden="true" fill="none" height="55" width="83" viewBox="0 0 25 32" xmlns="http://www.w3.org/2000/svg"><g transform="skewX(-20)"><path transform="scale(0.6, 1)" clip-rule="evenodd" d="M2 3.5C2 2.67157 2.67157 2 3.5 2C4.32843 2 5 2.67157 5 3.5V28.5C5 29.3284 4.32843 30 3.5 30C2.67157 30 2 29.3284 2 28.5V3.5ZM19 4C19 2.89543 19.8954 2 21 2H28C29.1046 2 30 2.89543 30 4V28C30 29.1046 29.1046 30 28 30H21C19.8954 30 19 29.1046 19 28V4ZM11 2C9.89543 2 9 2.89543 9 4V28C9 29.1046 9.89543 30 11 30H13C14.1046 30 15 29.1046 15 28V4C15 2.89543 14.1046 2 13 2H11Z" fill="currentColor" fill-rule="evenodd"></path></g></svg><span class="text-5xl -ml-12">\LAI</span></div></a><div class="md:hidden cursor-pointer"><svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path class="inline-flex" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path><path class="hidden" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path></svg></div><nav class="md:flex md:items-center hidden"><ul class="flex space-x-6"><li class="hover:text-teal-400 transition duration-300 cursor-pointer"><a href="/">Home</a></li><li class="hover:text-teal-400 transition duration-300 cursor-pointer"><a href="/about">About</a></li><li class="hover:text-teal-400 transition duration-300 cursor-pointer"><a href="/team">Team</a></li><li class="hover:text-teal-400 transition duration-300 cursor-pointer"><a href="/projects">Projects</a></li><li class="hover:text-teal-400 transition duration-300 cursor-pointer"><a href="/contact">Contact</a></li></ul></nav><div class="w-full h-screen top-0 left-0 bg-white dark:bg-slate-900 z-50 hidden md:hidden"><div class="absolute top-0 right-0 py-4 px-2 cursor-pointer"><svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path class="hidden" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"></path></svg></div><nav class="flex flex-col justify-center items-center text-center h-full"><ul class="flex flex-col space-y-6"><li class="hover:text-teal-400 transition duration-300 cursor-pointer"><a href="/">Home</a></li><li class="hover:text-teal-400 transition duration-300 cursor-pointer"><a href="/about">About</a></li><li class="hover:text-teal-400 transition duration-300 cursor-pointer"><a href="/team">Team</a></li><li class="hover:text-teal-400 transition duration-300 cursor-pointer"><a href="/projects">Projects</a></li><li class="hover:text-teal-400 transition duration-300 cursor-pointer"><a href="/contact">Contact</a></li></ul></nav></div></div></header><main class="mb-auto bg-slate-50 dark:bg-slate-900 text-slate-900 dark:text-slate-200"><div class="mx-2 md:mx-6 py-6"><div class="container mx-auto"><h1 class="text-6xl font-bold">News</h1></div><hr class="border-slate-600 dark:border-slate-400 my-6"/><div class="container mx-auto"><div class="flex justify-center flex-col gap-6"></div></div></div></main><footer class="text-xs px-2 md:px-6 pt-6 pb-12 w-full bg-gray-200 dark:bg-gray-900 text-gray-500 dark:text-gray-400"><div class="item-dark-enabled px-2 py-6 md:p-6 rounded-lg grid grid-cols-1 md:grid-cols-4 gap-6"><div class="col-span-4 py-6 md:py-0"><a href="/"><div class="flex items-center gap-0 text-teal-400 transition duration-300 hover:text-white cursor-pointer"><svg aria-hidden="true" fill="none" height="55" width="83" viewBox="0 0 25 32" xmlns="http://www.w3.org/2000/svg"><g transform="skewX(-20)"><path transform="scale(0.6, 1)" clip-rule="evenodd" d="M2 3.5C2 2.67157 2.67157 2 3.5 2C4.32843 2 5 2.67157 5 3.5V28.5C5 29.3284 4.32843 30 3.5 30C2.67157 30 2 29.3284 2 28.5V3.5ZM19 4C19 2.89543 19.8954 2 21 2H28C29.1046 2 30 2.89543 30 4V28C30 29.1046 29.1046 30 28 30H21C19.8954 30 19 29.1046 19 28V4ZM11 2C9.89543 2 9 2.89543 9 4V28C9 29.1046 9.89543 30 11 30H13C14.1046 30 15 29.1046 15 28V4C15 2.89543 14.1046 2 13 2H11Z" fill="currentColor" fill-rule="evenodd"></path></g></svg><span class="text-5xl -ml-12">\LAI</span></div></a></div><div class="col-span-1 md:col-span-4"><div class="rounded-lg px-2 py-6 mt-6"><div class="grid grid-cols-2 lg:grid-cols-4 gap-6"><div class="col-span-1 flex-col flex mb-4 lg:mb-0"><span class="font-bold text-lg mt-4">Phone</span><span>(936)-777-0513</span></div><div class="col-span-1 mb-4 lg:mb-0"><span class="font-bold text-lg">Try a model!</span><ul><a href="https://openchat.team/"><li class="hover:text-teal-400 transition duration-300 cursor-pointer">OpenChat.team</li></a></ul></div><div class="col-span-1 mb-4 lg:mb-0"><span class="font-bold text-lg">Follow Us!</span><br/><ul><a href="https://twitter.com/alignment_Lab"><li class="hover:text-teal-400 transition duration-300 cursor-pointer">X/Twitter</li></a><a href="https://discord.gg/ad27GQgc7K"><li class="hover:text-teal-400 transition duration-300 cursor-pointer">Discord</li></a><a href="https://huggingface.co/AlignmentLab-AI"><li class="hover:text-teal-400 transition duration-300 cursor-pointer">Huggingface</li></a></ul></div><div class="col-span-1 mb-4 lg:mb-0"><span class="font-bold text-lg">Legal</span><br/><ul><a href="/legal/terms"><li class="hover:text-teal-400 transition duration-300 cursor-pointer">Terms of Service</li></a><a href="/legal/privacy"><li class="hover:text-teal-400 transition duration-300 cursor-pointer">Privacy Policy</li></a></ul></div></div></div></div><div class="flex justify-between items-center gap-6 mt-6 col-span-4"><div>2024 ¬© All rights reserved.</div><div class="flex gap-2"><a class="group" href="https://huggingface.co/AlignmentLab-AI"><svg width="24" height="24" viewBox="0 0 256 256" fill="none" xmlns="http://www.w3.org/2000/svg" class="group-hover:fill-teal-400"><path class="fill-slate-400 dark:fill-slate-200 hover:fill-teal-400" fill-rule="evenodd" clip-rule="evenodd" d="M203.21 123.685V123.194C203.21 81.34 169.292 47.411 127.435 47.411C85.5791 47.411 51.648 81.342 51.648 123.194V123.358C51.646 123.467 51.645 123.576 51.648 123.685C51.6529 123.848 51.6546 124.011 51.653 124.174L51.6581 124.534L51.661 124.663C51.661 124.723 51.6631 124.782 51.6651 124.842C51.6681 124.937 51.67 125.033 51.67 125.128L51.681 125.517L51.697 125.974L51.702 126.124L51.722 126.597V126.62C51.73 126.805 51.7401 126.989 51.7491 127.173L51.75 127.187C51.76 127.375 51.7701 127.564 51.7821 127.753C51.7921 127.927 51.802 128.101 51.815 128.275L51.8171 128.306C51.8258 128.455 51.8358 128.605 51.847 128.754L51.85 128.794L51.883 129.226L51.8861 129.254C51.8921 129.338 51.898 129.422 51.906 129.503C51.9658 130.224 52.0355 130.945 52.1151 131.664L52.12 131.709L52.181 132.238L52.2491 132.793L52.299 133.17L52.322 133.347C52.3753 133.755 52.433 134.162 52.495 134.568L52.4991 134.595L52.558 134.979C52.8435 136.808 53.1971 138.626 53.618 140.429L53.6231 140.451L53.655 140.586L53.746 140.971L53.802 140.904C56.002 138.274 59.158 136.824 62.689 136.824C65.519 136.824 68.4221 137.76 71.3321 139.605C73.2621 140.831 75.3961 143.002 77.5921 145.733C79.6241 142.911 82.4721 141.035 85.7301 140.523C86.3513 140.425 86.9792 140.376 87.6081 140.375C95.0441 140.375 99.523 146.828 101.215 152.633C102.051 154.594 106.08 163.526 112.156 169.568C121.392 178.795 123.703 188.316 119.132 198.511H119.148C119.459 198.546 119.772 198.578 120.087 198.607C120.274 198.625 120.46 198.643 120.648 198.659L120.714 198.665L121.127 198.7L121.507 198.73C121.869 198.758 122.232 198.784 122.596 198.807L122.885 198.824L123.114 198.838L123.256 198.846L123.703 198.869L123.825 198.874L124.294 198.895L124.816 198.915L125.235 198.927L125.305 198.929C125.394 198.933 125.483 198.936 125.572 198.936L125.668 198.939C126.258 198.953 126.847 198.96 127.437 198.959H128.063L128.51 198.954C128.62 198.949 128.729 198.949 128.84 198.949H129.014L129.165 198.945C129.224 198.943 129.283 198.941 129.343 198.941H129.522L129.873 198.932L130.401 198.914L130.982 198.888C131.15 198.882 131.316 198.873 131.482 198.865L131.661 198.854L131.927 198.84L132.083 198.831L132.201 198.823L132.738 198.788L133.274 198.749L133.761 198.71L134.103 198.681L134.479 198.647C135.107 198.591 135.733 198.525 136.359 198.45L136.786 198.399C132.287 188.247 134.616 178.767 143.813 169.577C149.876 163.519 153.905 154.587 154.745 152.625C156.438 146.821 160.914 140.368 168.352 140.368C168.981 140.368 169.61 140.418 170.231 140.516C173.486 141.028 176.334 142.904 178.369 145.726C180.566 142.996 182.699 140.823 184.63 139.597C187.539 137.753 190.445 136.817 193.272 136.817C196.388 136.817 199.212 137.947 201.345 140.02C201.384 139.851 201.422 139.682 201.459 139.512L201.568 139.006C201.607 138.821 201.646 138.636 201.683 138.451C201.749 138.124 201.815 137.797 201.878 137.467C201.944 137.125 202.007 136.781 202.067 136.437L202.098 136.251C202.117 136.141 202.135 136.031 202.156 135.92C202.19 135.748 202.218 135.576 202.246 135.402L202.257 135.336L202.328 134.883L202.398 134.424V134.42C202.449 134.081 202.497 133.742 202.542 133.403L202.553 133.319L202.616 132.841L202.667 132.433L202.757 131.629L202.792 131.306L202.801 131.218C202.82 131.044 202.838 130.87 202.854 130.696V130.682C202.867 130.544 202.881 130.405 202.893 130.266C202.964 129.478 203.024 128.686 203.072 127.891C203.081 127.761 203.088 127.63 203.096 127.499V127.493L203.122 127.002L203.128 126.892C203.144 126.56 203.158 126.228 203.169 125.896V125.884L203.174 125.754C203.179 125.645 203.183 125.535 203.183 125.425L203.185 125.381C203.189 125.278 203.193 125.172 203.193 125.067L203.196 124.977C203.199 124.872 203.202 124.768 203.202 124.663L203.204 124.574C203.207 124.441 203.21 124.307 203.21 124.174V123.685ZM108.638 199.391C114.64 190.59 114.214 183.984 105.98 175.754C97.7441 167.523 92.951 155.487 92.951 155.487C92.951 155.487 91.1621 148.496 87.0821 149.138C83.0021 149.78 80.0091 160.227 88.5521 166.622C97.0941 173.017 86.8521 177.353 83.5641 171.352C80.2761 165.35 71.299 149.923 66.645 146.972C61.991 144.021 58.718 145.675 59.815 151.757C60.36 154.776 65.4281 159.929 70.1631 164.743C74.9671 169.627 79.428 174.163 78.474 175.768C76.581 178.955 69.9141 172.023 69.9141 172.023C69.9141 172.023 49.038 153.025 44.494 157.976C40.304 162.539 46.765 166.418 56.7211 172.397C57.5671 172.905 58.4391 173.429 59.3321 173.969C70.7231 180.865 71.609 182.684 69.992 185.293C69.395 186.257 65.582 183.968 60.892 181.153C52.897 176.352 42.3551 170.023 40.8661 175.688C39.5781 180.591 47.334 183.595 54.368 186.32C60.228 188.59 65.5881 190.666 64.7991 193.484C63.9821 196.406 59.5531 193.969 54.7121 191.305C49.2771 188.314 43.3221 185.038 41.3731 188.735C37.6901 195.725 66.7831 203.954 67.0231 204.015C76.4231 206.453 100.295 211.619 108.638 199.391ZM147.303 199.391C141.301 190.59 141.727 183.984 149.962 175.754C158.197 167.523 162.99 155.487 162.99 155.487C162.99 155.487 164.779 148.496 168.859 149.138C172.939 149.78 175.932 160.227 167.39 166.622C158.847 173.017 169.089 177.353 172.377 171.352C175.666 165.35 184.637 149.923 189.291 146.972C193.945 144.021 197.22 145.675 196.122 151.757C195.578 154.776 190.509 159.929 185.774 164.744C180.97 169.628 176.509 174.163 177.462 175.768C179.355 178.955 186.027 172.019 186.027 172.019C186.027 172.019 206.902 153.022 211.448 157.973C215.637 162.535 209.176 166.415 199.219 172.394C198.348 172.917 197.478 173.441 196.609 173.966C185.218 180.862 184.332 182.681 185.948 185.289C186.546 186.254 190.359 183.964 195.048 181.149C203.044 176.349 213.586 170.019 215.075 175.685C216.364 180.588 208.607 183.592 201.573 186.317C195.713 188.587 190.353 190.663 191.141 193.481C191.957 196.402 196.385 193.965 201.225 191.301C206.66 188.31 212.616 185.032 214.564 188.732C218.248 195.726 189.15 203.947 188.915 204.007C179.515 206.453 155.643 211.619 147.303 199.391Z"></path><path class="fill-slate-800 dark:fill-slate-800 hover:fill-teal-400" fill-rule="evenodd" clip-rule="evenodd" d="M152.047 102.567C153.229 102.985 154.108 104.257 154.944 105.468C156.074 107.104 157.126 108.627 158.74 107.769C160.644 106.756 162.205 105.202 163.225 103.302C164.246 101.402 164.681 99.2427 164.475 97.096C164.321 95.4908 163.813 93.9398 162.987 92.5548C162.161 91.1697 161.038 89.985 159.7 89.0862C158.361 88.1874 156.839 87.5968 155.245 87.3569C153.65 87.117 152.022 87.2339 150.478 87.699C148.934 88.1639 147.513 88.9653 146.316 90.0455C145.119 91.1257 144.176 92.4578 143.556 93.946C142.936 95.4342 142.653 97.0415 142.728 98.652C142.804 100.263 143.235 101.836 143.992 103.26C144.74 104.667 146.4 104.003 148.152 103.302C149.525 102.753 150.956 102.181 152.047 102.567ZM100.672 102.567C99.49 102.985 98.611 104.258 97.775 105.468C96.645 107.105 95.592 108.627 93.979 107.769C91.5845 106.501 89.7482 104.386 88.8278 101.838C87.9075 99.2895 87.9692 96.4896 89.0008 93.9841C90.0324 91.4786 91.9601 89.4471 94.408 88.2855C96.856 87.1239 99.6488 86.9156 102.242 87.701C104.307 88.3228 106.141 89.5427 107.513 91.2065C108.885 92.8704 109.732 94.9035 109.949 97.049C110.165 99.1945 109.74 101.356 108.728 103.26C107.979 104.667 106.319 104.003 104.567 103.303C103.193 102.753 101.764 102.181 100.672 102.567ZM144.099 149.318C152.242 142.903 155.233 132.429 155.233 125.977C155.233 120.877 151.802 122.482 146.309 125.202L145.999 125.355C140.957 127.852 134.245 131.177 126.877 131.177C119.508 131.177 112.796 127.852 107.755 125.354C102.084 122.545 98.527 120.783 98.527 125.978C98.527 132.634 101.709 143.563 110.443 149.912C111.596 147.573 113.219 145.497 115.211 143.813C117.202 142.129 119.52 140.874 122.018 140.126C122.89 139.866 123.788 141.367 124.707 142.904C125.594 144.386 126.501 145.902 127.423 145.902C128.406 145.902 129.371 144.408 130.314 142.95C131.299 141.425 132.26 139.94 133.189 140.237C137.864 141.738 141.775 144.993 144.099 149.318Z"></path></svg></a><a href="/news"><svg xmlns="http://www.w3.org/2000/svg" x="0px" y="0px" width="24" height="24" viewBox="0 0 30 30" class="fill-slate-900 dark:fill-slate-200 hover:fill-teal-400"><path d="M24,4H6C4.895,4,4,4.895,4,6v18c0,1.105,0.895,2,2,2h18c1.105,0,2-0.895,2-2V6C26,4.895,25.105,4,24,4z M10.954,22h-2.95 v-9.492h2.95V22z M9.449,11.151c-0.951,0-1.72-0.771-1.72-1.72c0-0.949,0.77-1.719,1.72-1.719c0.948,0,1.719,0.771,1.719,1.719 C11.168,10.38,10.397,11.151,9.449,11.151z M22.004,22h-2.948v-4.616c0-1.101-0.02-2.517-1.533-2.517 c-1.535,0-1.771,1.199-1.771,2.437V22h-2.948v-9.492h2.83v1.297h0.04c0.394-0.746,1.356-1.533,2.791-1.533 c2.987,0,3.539,1.966,3.539,4.522V22z"></path></svg></a><a href="https://github.com/alignment-lab-ai"><svg xmlns="http://www.w3.org/2000/svg" x="0px" y="0px" width="24" height="24" viewBox="0 0 30 30" class="fill-slate-900 dark:fill-slate-200 hover:fill-teal-400"><path d="M15,3C8.373,3,3,8.373,3,15c0,5.623,3.872,10.328,9.092,11.63C12.036,26.468,12,26.28,12,26.047v-2.051 c-0.487,0-1.303,0-1.508,0c-0.821,0-1.551-0.353-1.905-1.009c-0.393-0.729-0.461-1.844-1.435-2.526 c-0.289-0.227-0.069-0.486,0.264-0.451c0.615,0.174,1.125,0.596,1.605,1.222c0.478,0.627,0.703,0.769,1.596,0.769 c0.433,0,1.081-0.025,1.691-0.121c0.328-0.833,0.895-1.6,1.588-1.962c-3.996-0.411-5.903-2.399-5.903-5.098 c0-1.162,0.495-2.286,1.336-3.233C9.053,10.647,8.706,8.73,9.435,8c1.798,0,2.885,1.166,3.146,1.481C13.477,9.174,14.461,9,15.495,9 c1.036,0,2.024,0.174,2.922,0.483C18.675,9.17,19.763,8,21.565,8c0.732,0.731,0.381,2.656,0.102,3.594 c0.836,0.945,1.328,2.066,1.328,3.226c0,2.697-1.904,4.684-5.894,5.097C18.199,20.49,19,22.1,19,23.313v2.734 c0,0.104-0.023,0.179-0.035,0.268C23.641,24.676,27,20.236,27,15C27,8.373,21.627,3,15,3z"></path></svg></a><a href="https://twitter.com/alignment_Lab"><svg xmlns="http://www.w3.org/2000/svg" x="0px" y="0px" width="24" height="24" viewBox="0 0 30 30" class="fill-slate-900 dark:fill-slate-200 hover:fill-teal-400"><path d="M26.37,26l-8.795-12.822l0.015,0.012L25.52,4h-2.65l-6.46,7.48L11.28,4H4.33l8.211,11.971L12.54,15.97L3.88,26h2.65 l7.182-8.322L19.42,26H26.37z M10.23,6l12.34,18h-2.1L8.12,6H10.23z"></path></svg></a><a href="https://discord.gg/ad27GQgc7K"><svg xmlns="http://www.w3.org/2000/svg" x="0px" y="0px" width="24" height="24" viewBox="0 0 30 30" class="fill-slate-900 dark:fill-slate-200 hover:fill-teal-400"><path d="M12.345,6.236c-0.218-0.606-0.438-1.217-0.442-1.225c-0.105-0.235-0.348-0.383-0.604-0.357 c-0.162,0.013-3.995,0.343-6.451,2.318C3.564,8.158,1,15.092,1,21.087c0,0.106,0.027,0.209,0.08,0.301 c1.771,3.11,6.599,3.924,7.699,3.959c0.007,0.001,0.013,0.001,0.019,0.001c0.194,0,0.376-0.093,0.492-0.25l1.19-1.612 c-1.966-0.299-2.321-0.689-2.404-0.75c-0.444-0.327-0.772-0.785-0.374-1.363c0.306-0.449,0.948-0.597,1.44-0.344 C9.646,21.264,10.995,22.02,15,22c3.977-0.012,5.723-0.845,5.748-0.863c0.668-0.301,1.189-0.177,1.514,0.269 c0.387,0.607,0.111,1.018-0.331,1.344c-0.083,0.061-0.284,0.232-2.396,0.732l1.175,1.615c0.115,0.158,0.298,0.25,0.492,0.25 c0.007,0,0.013,0,0.019-0.001c1.101-0.035,5.929-0.849,7.699-3.959c0.053-0.092,0.08-0.195,0.08-0.301 c0-5.994-2.564-12.928-3.88-14.14c-2.424-1.948-6.257-2.278-6.419-2.292c-0.256-0.022-0.499,0.123-0.604,0.357 c-0.004,0.008-0.218,0.629-0.425,1.228C17.672,6.239,16.041,6,15,6S12.345,6.236,12.345,6.236z M11,19c-1.105,0-2-1.333-2-2.979 s0.895-2.979,2-2.979c1.109-0.165,1.976,1.333,2,2.979C13,17.667,12.105,19,11,19z M19,19c-1.105,0-2-1.342-2-2.997 s0.895-2.997,2-2.997s2,1.342,2,2.997S20.105,19,19,19z"></path></svg></a></div></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json" crossorigin="">{"props":{"pageProps":{"allNewsData":[{"id":"greatchat","license":"apache-2.0","tags":["openchat","mistral","C-RLFT"],"datasets":["openchat/openchat_sharegpt4_dataset","kaist-ai/Feedback-Collection","imone/OpenOrca_FLAN","LDJnr/LessWrong-Amplify-Instruct","LDJnr/Pure-Dove","LDJnr/Verified-Camel","tiedong/goat","glaiveai/glaive-code-assistant","meta-math/MetaMathQA","OpenAssistant/oasst_top1_2023-08-25","TIGER-Lab/MathInstruct"],"library_name":"transformers","pipeline_tag":"text-generation","processedContent":"\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"https://raw.githubusercontent.com/imoneoi/openchat/master/assets/logo_new.png\" style=\"width: 65%\"\u003e\n  \u003ch1\u003eAdvancing Open-source Language Models with Mixed-Quality Data\u003c/h1\u003e\n\u003c/div\u003e\n\n\u003cp align=\"center\" style=\"margin-top: 0px;\"\u003e\n  \u003ca href=\"https://openchat.team\"\u003e\n    \u003cimg src=\"https://github.com/alpayariyak/openchat/blob/master/assets/logo_nobg.png?raw=true\" alt=\"OpenChat Logo\" style=\"width:20px; vertical-align: middle; display: inline-block; margin-right: 5px; margin-left: 10px; margin-top: 0px; margin-bottom: 0px;\"/\u003e\n    \u003cspan class=\"link-text\" style=\" margin-right: 5px;\"\u003eOnline Demo\u003c/span\u003e\n  \u003c/a\u003e |\n  \u003ca href=\"https://github.com/imoneoi/openchat\"\u003e\n    \u003cimg src=\"https://camo.githubusercontent.com/4133dc1cd4511d4a292b84ce10e52e4ed92569fb2a8165381c9c47be5edc2796/68747470733a2f2f6564656e742e6769746875622e696f2f537570657254696e7949636f6e732f696d616765732f706e672f6769746875622e706e67\" alt=\"GitHub Logo\" style=\"width:20px; vertical-align: middle; display: inline-block; margin-right: 5px; margin-left: 5px; margin-top: 0px; margin-bottom: 0px;\"/\u003e\n    \u003cspan class=\"link-text\" style=\" margin-right: 5px;\"\u003eGitHub\u003c/span\u003e\n  \u003c/a\u003e |\n  \u003ca href=\"https://arxiv.org/pdf/2309.11235.pdf\"\u003e\n    \u003cimg src=\"https://github.com/alpayariyak/openchat/blob/master/assets/arxiv-logomark-small-square-border.png?raw=true\" alt=\"ArXiv Logo\" style=\"width:20px; vertical-align: middle; display: inline-block; margin-right: 5px; margin-left: 5px; margin-top: 0px; margin-bottom: 0px;\"/\u003e\n    \u003cspan class=\"link-text\" style=\"margin-right: 5px;\"\u003ePaper\u003c/span\u003e\n  \u003c/a\u003e |\n  \u003ca href=\"https://discord.gg/pQjnXvNKHY\"\u003e\n    \u003cimg src=\"https://cloud.githubusercontent.com/assets/6291467/26705903/96c2d66e-477c-11e7-9f4e-f3c0efe96c9a.png\" alt=\"Discord Logo\" style=\"width:20px; vertical-align: middle; display: inline-block; margin-right: 5px; margin-left: 5px; margin-top: 0px; margin-bottom: 0px;\"/\u003e\n    \u003cspan class=\"link-text\"\u003eDiscord\u003c/span\u003e\n  \u003c/a\u003e\n\u003c/p\u003e\n\n\u003chr\u003e\n\u003cdiv style=\"background-color: white; padding: 0.7em; border-radius: 0.5em; color: black; display: flex; flex-direction: column; justify-content: center; text-align: center; ont-size: 0.5em;\"\u003e\n  \u003ca href=\"https://huggingface.co/openchat/openchat_3.5\" style=\"text-decoration: none; color: black;\"\u003e\n    \u003cspan style=\"font-size: 1.7em; font-family: 'Helvetica'; letter-spacing: 0.1em; font-weight: bold; color: black;\"\u003eOPENCHAT\u003c/span\u003e\u003cspan style=\"font-size: 1.8em; font-family: 'Helvetica'; color: #3c72db; \"\u003e3.5\u003c/span\u003e\n        \u003cspan style=\"font-size: 0.7em;  font-family: 'Helvetica'; color:  white; vertical-align: top;  background-color:red;  border-radius: 6em; padding: 0.066em 0.4em; letter-spacing: 0.1em; font-weight: bold;\"\u003e1210\u003c/span\u003e\n    \u003cspan style=\"font-size: 0.85em; font-family: 'Helvetica'; color: black;\"\u003e\n      \u003cbr\u003e üèÜ The Overall Best Performing Open Source 7B Model üèÜ\n    \u003cbr\u003e ü§ñ Outperforms \u003cspan style=\"font-weight: bold;\"\u003eChatGPT\u003c/span\u003e (March) and \u003cspan style=\"font-weight: bold;\"\u003eGrok-1\u003c/span\u003e ü§ñ\n      \u003cbr\u003e üöÄ\u003cspan style=\"font-size: 1em; font-family: 'Helvetica'; color: black; font-weight: bold;\"\u003e15\u003c/span\u003e-point improvement in Coding over \u003cspan style=\"font-size: 0.9em;\n      font-family: 'Helvetica'; color: black; font-weight: bold;\"\u003eOpenChat-3.5üöÄ\u003c/span\u003e\n      \u003cbr\u003e\u003cbr\u003e\u003cspan style=\"font-size: 1em; font-family: 'Helvetica'; color: #3c72db; font-weight: bold;\"\u003eNew Features\u003c/span\u003e\n      \u003cbr\u003e üí° 2 Modes: Coding + Generalist, Mathematical Reasoning üí°\n      \u003cbr\u003e üßë‚Äç‚öñÔ∏è Experimental support for Evaluator and Feedback capabilities üßë‚Äç‚öñÔ∏è\n    \u003c/span\u003e\n  \u003c/a\u003e\n\u003c/div\u003e\n\n\u003cdiv style=\"display: flex; justify-content: center; align-items: center\"\u003e\n  \u003cimg src=\"https://github.com/alpayariyak/openchat/blob/master/assets/1210bench.png?raw=true\" style=\"width: 100%; border-radius: 1em\"\u003e\n\u003c/div\u003e\n\n\u003cdiv\u003e\n\u003ch3\u003e Table of Contents\u003c/h3\u003e\n\u003c/div\u003e\n\n1. [Usage](#usage)\n2. [Benchmarks](#benchmarks)\n3. [Limitations](#limitations)\n4. [License](#license)\n5. [Dataset Details](#dataset-details)\n6. [Citation](#citation)\n7. [Acknowledgements](#acknowledgements)\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e Usage \u003c/h2\u003e\n\u003c/div\u003e\n\nTo use this model, we highly recommend installing the OpenChat package by following the [installation guide](https://github.com/imoneoi/openchat#installation) in our repository and using the OpenChat OpenAI-compatible API server by running the serving command from the table below. The server is optimized for high-throughput deployment using [vLLM](https://github.com/vllm-project/vllm) and can run on a consumer GPU with 24GB RAM. To enable tensor parallelism, append `--tensor-parallel-size N` to the serving command.\n\nOnce started, the server listens at `localhost:18888` for requests and is compatible with the [OpenAI ChatCompletion API specifications](https://platform.openai.com/docs/api-reference/chat). Please refer to the example request below for reference. Additionally, you can use the [OpenChat Web UI](https://github.com/imoneoi/openchat#web-ui) for a user-friendly experience.\n\nIf you want to deploy the server as an online service, you can use `--api-keys sk-KEY1 sk-KEY2 ...` to specify allowed API keys and `--disable-log-requests --disable-log-stats --log-file openchat.log` for logging only to a file. For security purposes, we recommend using an [HTTPS gateway](https://fastapi.tiangolo.com/es/deployment/concepts/#security-https) in front of the server.\n\n| OpenChat 3.5 1210 | 7B | 8192 | [Huggingface](https://huggingface.co/openchat/openchat_3.5_1210) | `python -m ochat.serving.openai_api_server --model openchat/openchat_3.5_1210 --engine-use-ray --worker-use-ray` |\n\n\u003cdetails\u003e\n  \u003csummary\u003eExample request (click to expand)\u003c/summary\u003e\n\nüí° **Default Mode (GPT4 Correct)**: Best for coding, chat and general tasks\n\n```bash\ncurl http://localhost:18888/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"openchat_3.5\",\n    \"messages\": [{\"role\": \"user\", \"content\": \"You are a large language model named OpenChat. Write a poem to describe yourself\"}]\n  }'\n```\n\nüßÆ **Mathematical Reasoning Mode**: Tailored for solving math problems\n\n```bash\ncurl http://localhost:18888/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"openchat_3.5\",\n    \"condition\": \"Math Correct\",\n    \"messages\": [{\"role\": \"user\", \"content\": \"10.3 ‚àí 7988.8133 = \"}]\n  }'\n```\n\n\u003c/details\u003e\n\n### Conversation templates\n\nüí° **Default Mode (GPT4 Correct)**: Best for coding, chat and general tasks\n\n```\nGPT4 Correct User: Hello\u003c|end_of_turn|\u003eGPT4 Correct Assistant: Hi\u003c|end_of_turn|\u003eGPT4 Correct User: How are you today?\u003c|end_of_turn|\u003eGPT4 Correct Assistant:\n```\n\nüßÆ **Mathematical Reasoning Mode**: Tailored for solving math problems\n\n```\nMath Correct User: 10.3 ‚àí 7988.8133=\u003c|end_of_turn|\u003eMath Correct Assistant:\n```\n\n‚ö†Ô∏è **Notice:** Remember to set `\u003c|end_of_turn|\u003e` as end of generation token.\n\nThe default (GPT4 Correct) template is also available as the integrated `tokenizer.chat_template`,\nwhich can be used instead of manually specifying the template:\n\n```python\nmessages = [\n    {\"role\": \"user\", \"content\": \"Hello\"},\n    {\"role\": \"assistant\", \"content\": \"Hi\"},\n    {\"role\": \"user\", \"content\": \"How are you today?\"}\n]\ntokens = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\nassert tokens == [1, 420, 6316, 28781, 3198, 3123, 1247, 28747, 22557, 32000, 420, 6316, 28781, 3198, 3123, 21631, 28747, 15359, 32000, 420, 6316, 28781, 3198, 3123, 1247, 28747, 1602, 460, 368, 3154, 28804, 32000, 420, 6316, 28781, 3198, 3123, 21631, 28747]\n```\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e (Experimental) Evaluator / Feedback Capabilities \u003c/h2\u003e\n\u003c/div\u003e\nWe've included evaluator capabilities in this release to advance open-source models as evaluators. You can use `Default Mode (GPT4 Correct)` with the following prompt (same as [Prometheus](https://huggingface.co/datasets/kaist-ai/Feedback-Collection)) to evaluate a response.\n\n```\n###Task Description:\nAn instruction (might include an Input inside it), a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing a evaluation criteria are given.\n1. Write a detailed feedback that assess the quality of the response strictly based on the given score rubric, not evaluating in general.\n2. After writing a feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric.\n3. The output format should look as follows: \"Feedback: (write a feedback for criteria) [RESULT] (an integer number between 1 and 5)\"\n4. Please do not generate any other opening, closing, and explanations.\n\n###The instruction to evaluate:\n{orig_instruction}\n\n###Response to evaluate:\n{orig_response}\n\n###Reference Answer (Score 5):\n{orig_reference_answer}\n\n###Score Rubrics:\n[{orig_criteria}]\nScore 1: {orig_score1_description}\nScore 2: {orig_score2_description}\nScore 3: {orig_score3_description}\nScore 4: {orig_score4_description}\nScore 5: {orig_score5_description}\n\n###Feedback:\n```\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e Benchmarks \u003c/h2\u003e\n\u003c/div\u003e\n\n| Model             | # Params | Average  | MT-Bench | HumanEval | BBH MC   | AGIEval  | TruthfulQA | MMLU     | GSM8K    | BBH CoT  |\n| ----------------- | -------- | -------- | -------- | --------- | -------- | -------- | ---------- | -------- | -------- | -------- |\n| OpenChat-3.5-1210 | **7B**   | **63.8** | 7.76     | **68.9**  | **49.5** | **48.0** | **61.8**   | 65.3     | **77.3** | 61.8     |\n| OpenChat-3.5      | **7B**   | 61.6     | 7.81     | 55.5      | 47.6     | 47.4     | 59.1       | 64.3     | **77.3** | 63.5     |\n| ChatGPT (March)\\* | ?        | 61.5     | **7.94** | 48.1      | 47.6     | 47.1     | 57.7       | **67.3** | 74.9     | **70.1** |\n|                   |          |          |          |           |          |          |            |          |          |          |\n| OpenHermes 2.5    | 7B       | 59.3     | 7.54     | 48.2      | 49.4     | 46.5     | 57.5       | 63.8     | 73.5     | 59.9     |\n| OpenOrca Mistral  | 7B       | 52.7     | 6.86     | 38.4      | 49.4     | 42.9     | 45.9       | 59.3     | 59.1     | 58.1     |\n| Zephyr-Œ≤^         | 7B       | 34.6     | 7.34     | 22.0      | 40.6     | 39.0     | 40.8       | 39.8     | 5.1      | 16.0     |\n| Mistral           | 7B       | -        | 6.84     | 30.5      | 39.0     | 38.0     | -          | 60.1     | 52.2     | -        |\n\n\u003cdetails\u003e\n  \u003csummary\u003eEvaluation Details(click to expand)\u003c/summary\u003e\n*: ChatGPT (March) results are from [GPT-4 Technical Report](https://arxiv.org/abs/2303.08774), [Chain-of-Thought Hub](https://github.com/FranxYao/chain-of-thought-hub), and our evaluation. Please note that ChatGPT is not a fixed baseline and evolves rapidly over time.\n\n^: Zephyr-Œ≤ often fails to follow few-shot CoT instructions, likely because it was aligned with only chat data but not trained on few-shot data.\n\n\\*\\*: Mistral and Open-source SOTA results are taken from reported results in instruction-tuned model papers and official repositories.\n\nAll models are evaluated in chat mode (e.g. with the respective conversation template applied). All zero-shot benchmarks follow the same setting as in the AGIEval paper and Orca paper. CoT tasks use the same configuration as Chain-of-Thought Hub, HumanEval is evaluated with EvalPlus, and MT-bench is run using FastChat. To reproduce our results, follow the instructions in [our repository](https://github.com/imoneoi/openchat/#benchmarks).\n\n\u003c/details\u003e\n\u003cdiv\u003e\n\u003ch3\u003eHumanEval+\u003c/h3\u003e\n\u003c/div\u003e\n\n| Model                       | Size   | HumanEval+ pass@1 |\n| --------------------------- | ------ | ----------------- |\n| ChatGPT (December 12, 2023) | -      | 64.6              |\n| WizardCoder-Python-34B-V1.0 | 34B    | 64.6              |\n| **OpenChat 3.5 (Dec 10)**   | **7B** | **63.4**          |\n| OpenHermes 2.5              | 7B     | 41.5              |\n\n\u003cdiv\u003e\n\u003ch3\u003eOpenChat-3.5-1210 vs. Grok\u003c/h3\u003e\n\u003c/div\u003e\n\n|                   | License     | # Param | Average  | MMLU | HumanEval | MATH     | GSM8k    |\n| ----------------- | ----------- | ------- | -------- | ---- | --------- | -------- | -------- |\n| OpenChat 3.5 1210 | Apache-2.0  | **7B**  | **60.1** | 65.3 | **68.9**  | **28.9** | **77.3** |\n| OpenChat 3.5      | Apache-2.0  | **7B**  | 56.4     | 64.3 | 55.5      | 28.6     | **77.3** |\n| Grok-0            | Proprietary | 33B     | 44.5     | 65.7 | 39.7      | 15.7     | 56.8     |\n| Grok-1            | Proprietary | ???B    | 55.8     | 73   | 63.2      | 23.9     | 62.9     |\n\n\\*: Grok results are reported by [X.AI](https://x.ai/).\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e ‰∏≠ÊñáËØÑ‰º∞ÁªìÊûú / Chinese Evaluations \u003c/h2\u003e\n\u003c/div\u003e\n\n‚ö†Ô∏è Note that this model was not explicitly trained in Chinese (only \u003c 0.1% of the data is in Chinese). ËØ∑Ê≥®ÊÑèÊú¨Ê®°ÂûãÊ≤°ÊúâÈíàÂØπÊÄßËÆ≠ÁªÉ‰∏≠ÊñáÔºà‰∏≠ÊñáÊï∞ÊçÆÂç†ÊØîÂ∞è‰∫é 0.1%Ôºâ„ÄÇ\n\n\u003cdiv\u003e\n\u003ch3\u003eMulti-Level Multi-Discipline Chinese Evaluation Suite (CEVAL)\u003c/h3\u003e\n\u003cdiv\u003e\n\n| Model    | Avg   | STEM  | Social Science | Humanities | Others |\n| -------- | ----- | ----- | -------------- | ---------- | ------ |\n| ChatGPT  | 54.4  | 52.9  | 61.8           | 50.9       | 53.6   |\n| OpenChat | 47.29 | 45.22 | 52.49          | 48.52      | 45.08  |\n\n\u003cdiv\u003e\n\u003ch3\u003eMassive Multitask Language Understanding in Chinese (CMMLU, 5-shot)\u003c/h3\u003e\n\u003c/div\u003e\n\n| Models   | STEM  | Humanities | SocialSciences | Other | ChinaSpecific | Avg   |\n| -------- | ----- | ---------- | -------------- | ----- | ------------- | ----- |\n| ChatGPT  | 47.81 | 55.68      | 56.5           | 62.66 | 50.69         | 55.51 |\n| OpenChat | 38.7  | 45.99      | 48.32          | 50.23 | 43.27         | 45.85 |\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e Limitations \u003c/h2\u003e\n\u003c/div\u003e\n\n**Foundation Model Limitations**\nDespite its advanced capabilities, OpenChat is still bound by the limitations inherent in its foundation models. These limitations may impact the model's performance in areas such as:\n\n- Complex reasoning\n- Mathematical and arithmetic tasks\n- Programming and coding challenges\n\n**Hallucination of Non-existent Information**\nOpenChat may sometimes generate information that does not exist or is not accurate, also known as \"hallucination\". Users should be aware of this possibility and verify any critical information obtained from the model.\n\n**Safety**\nOpenChat may sometimes generate harmful, hate speech, biased responses, or answer unsafe questions. It's crucial to apply additional AI safety measures in use cases that require safe and moderated responses.\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e License \u003c/h2\u003e\n\u003c/div\u003e\n\nOur OpenChat 3.5 code and models are distributed under the Apache License 2.0.\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e Dataset Details \u003c/h2\u003e\n\u003c/div\u003e\n\nOpenChat 3.5 was trained with C-RLFT on a collection of publicly available high-quality instruction data, with a custom processing pipeline. We detail some notable subsets included here:\n\n- [OpenChat ShareGPT](https://huggingface.co/datasets/openchat/openchat_sharegpt4_dataset)\n- [Open-Orca with FLAN answers](https://huggingface.co/datasets/imone/OpenOrca_FLAN)\n- [Feedback-Collection](https://huggingface.co/datasets/kaist-ai/Feedback-Collection)\n- Capybara [1](https://huggingface.co/datasets/LDJnr/Pure-Dove) [2](https://huggingface.co/datasets/LDJnr/Verified-Camel) [3](https://huggingface.co/datasets/LDJnr/LessWrong-Amplify-Instruct)\n- [GOAT](https://huggingface.co/datasets/tiedong/goat)\n- [Glaive](https://huggingface.co/datasets/glaiveai/glaive-code-assistant)\n- [MetaMathQA](https://huggingface.co/datasets/meta-math/MetaMathQA)\n- [MathInstruct](https://huggingface.co/datasets/TIGER-Lab/MathInstruct)\n- [OpenAssistant](https://huggingface.co/datasets/OpenAssistant/oasst_top1_2023-08-25)\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e Citation \u003c/h2\u003e\n\u003c/div\u003e\n\n```\n@article{wang2023openchat,\n  title={OpenChat: Advancing Open-source Language Models with Mixed-Quality Data},\n  author={Wang, Guan and Cheng, Sijie and Zhan, Xianyuan and Li, Xiangang and Song, Sen and Liu, Yang},\n  journal={arXiv preprint arXiv:2309.11235},\n  year={2023}\n}\n```\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e Acknowledgments \u003c/h2\u003e\n\u003c/div\u003e\n\nWe extend our heartfelt gratitude to AutoMeta and caesus from Alignment Lab AI, LDJ and Teknium from Nous Research, alpin and TearGosling from Pygmalion AI for their substantial contributions to data collection and model training.\n\nSpecial thanks go to Changling Liu from GPT Desk Pte. Ltd., Qiying Yu at Tsinghua University, Baochang Ma, and Hao Wan from 01.AI company for their generous provision of resources. We are also deeply grateful to Jianxiong Li and Peng Li at Tsinghua University for their insightful discussions.\n\nFurthermore, we appreciate the developers behind the following projects for their significant contributions to our research: [Mistral](https://mistral.ai/), [Chain-of-Thought Hub](https://github.com/FranxYao/chain-of-thought-hub), [Llama 2](https://ai.meta.com/llama/), [Self-Instruct](https://arxiv.org/abs/2212.10560), [FastChat (Vicuna)](https://github.com/lm-sys/FastChat), [Alpaca](https://github.com/tatsu-lab/stanford_alpaca.git), and [StarCoder](https://github.com/bigcode-project/starcoder). Their work has been instrumental in driving our research forward.\n"},{"id":"openchat","license":"apache-2.0","tags":["openchat","mistral","C-RLFT"],"datasets":["openchat/openchat_sharegpt4_dataset","kaist-ai/Feedback-Collection","imone/OpenOrca_FLAN","LDJnr/LessWrong-Amplify-Instruct","LDJnr/Pure-Dove","LDJnr/Verified-Camel","tiedong/goat","glaiveai/glaive-code-assistant","meta-math/MetaMathQA","OpenAssistant/oasst_top1_2023-08-25","TIGER-Lab/MathInstruct"],"library_name":"transformers","pipeline_tag":"text-generation","processedContent":"\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"https://raw.githubusercontent.com/imoneoi/openchat/master/assets/logo_new.png\" style=\"width: 65%\"\u003e\n  \u003ch1\u003eAdvancing Open-source Language Models with Mixed-Quality Data\u003c/h1\u003e\n\u003c/div\u003e\n\n\u003cp align=\"center\" style=\"margin-top: 0px;\"\u003e\n  \u003ca href=\"https://openchat.team\"\u003e\n    \u003cimg src=\"https://github.com/alpayariyak/openchat/blob/master/assets/logo_nobg.png?raw=true\" alt=\"OpenChat Logo\" style=\"width:20px; vertical-align: middle; display: inline-block; margin-right: 5px; margin-left: 10px; margin-top: 0px; margin-bottom: 0px;\"/\u003e\n    \u003cspan class=\"link-text\" style=\" margin-right: 5px;\"\u003eOnline Demo\u003c/span\u003e\n  \u003c/a\u003e |\n  \u003ca href=\"https://github.com/imoneoi/openchat\"\u003e\n    \u003cimg src=\"https://camo.githubusercontent.com/4133dc1cd4511d4a292b84ce10e52e4ed92569fb2a8165381c9c47be5edc2796/68747470733a2f2f6564656e742e6769746875622e696f2f537570657254696e7949636f6e732f696d616765732f706e672f6769746875622e706e67\" alt=\"GitHub Logo\" style=\"width:20px; vertical-align: middle; display: inline-block; margin-right: 5px; margin-left: 5px; margin-top: 0px; margin-bottom: 0px;\"/\u003e\n    \u003cspan class=\"link-text\" style=\" margin-right: 5px;\"\u003eGitHub\u003c/span\u003e\n  \u003c/a\u003e |\n  \u003ca href=\"https://arxiv.org/pdf/2309.11235.pdf\"\u003e\n    \u003cimg src=\"https://github.com/alpayariyak/openchat/blob/master/assets/arxiv-logomark-small-square-border.png?raw=true\" alt=\"ArXiv Logo\" style=\"width:20px; vertical-align: middle; display: inline-block; margin-right: 5px; margin-left: 5px; margin-top: 0px; margin-bottom: 0px;\"/\u003e\n    \u003cspan class=\"link-text\" style=\"margin-right: 5px;\"\u003ePaper\u003c/span\u003e\n  \u003c/a\u003e |\n  \u003ca href=\"https://discord.gg/pQjnXvNKHY\"\u003e\n    \u003cimg src=\"https://cloud.githubusercontent.com/assets/6291467/26705903/96c2d66e-477c-11e7-9f4e-f3c0efe96c9a.png\" alt=\"Discord Logo\" style=\"width:20px; vertical-align: middle; display: inline-block; margin-right: 5px; margin-left: 5px; margin-top: 0px; margin-bottom: 0px;\"/\u003e\n    \u003cspan class=\"link-text\"\u003eDiscord\u003c/span\u003e\n  \u003c/a\u003e\n\u003c/p\u003e\n\n\u003chr\u003e\n\u003cdiv style=\"background-color: white; padding: 0.7em; border-radius: 0.5em; color: black; display: flex; flex-direction: column; justify-content: center; text-align: center; ont-size: 0.5em;\"\u003e\n  \u003ca href=\"https://huggingface.co/openchat/openchat_3.5\" style=\"text-decoration: none; color: black;\"\u003e\n    \u003cspan style=\"font-size: 1.7em; font-family: 'Helvetica'; letter-spacing: 0.1em; font-weight: bold; color: black;\"\u003eOPENCHAT\u003c/span\u003e\u003cspan style=\"font-size: 1.8em; font-family: 'Helvetica'; color: #3c72db; \"\u003e3.5\u003c/span\u003e\n        \u003cspan style=\"font-size: 0.7em;  font-family: 'Helvetica'; color:  white; vertical-align: top;  background-color:red;  border-radius: 6em; padding: 0.066em 0.4em; letter-spacing: 0.1em; font-weight: bold;\"\u003e1210\u003c/span\u003e\n    \u003cspan style=\"font-size: 0.85em; font-family: 'Helvetica'; color: black;\"\u003e\n      \u003cbr\u003e üèÜ The Overall Best Performing Open Source 7B Model üèÜ\n    \u003cbr\u003e ü§ñ Outperforms \u003cspan style=\"font-weight: bold;\"\u003eChatGPT\u003c/span\u003e (March) and \u003cspan style=\"font-weight: bold;\"\u003eGrok-1\u003c/span\u003e ü§ñ\n      \u003cbr\u003e üöÄ\u003cspan style=\"font-size: 1em; font-family: 'Helvetica'; color: black; font-weight: bold;\"\u003e15\u003c/span\u003e-point improvement in Coding over \u003cspan style=\"font-size: 0.9em;\n      font-family: 'Helvetica'; color: black; font-weight: bold;\"\u003eOpenChat-3.5üöÄ\u003c/span\u003e\n      \u003cbr\u003e\u003cbr\u003e\u003cspan style=\"font-size: 1em; font-family: 'Helvetica'; color: #3c72db; font-weight: bold;\"\u003eNew Features\u003c/span\u003e\n      \u003cbr\u003e üí° 2 Modes: Coding + Generalist, Mathematical Reasoning üí°\n      \u003cbr\u003e üßë‚Äç‚öñÔ∏è Experimental support for Evaluator and Feedback capabilities üßë‚Äç‚öñÔ∏è\n    \u003c/span\u003e\n  \u003c/a\u003e\n\u003c/div\u003e\n\n\u003cdiv style=\"display: flex; justify-content: center; align-items: center\"\u003e\n  \u003cimg src=\"https://github.com/alpayariyak/openchat/blob/master/assets/1210bench.png?raw=true\" style=\"width: 100%; border-radius: 1em\"\u003e\n\u003c/div\u003e\n\n\u003cdiv\u003e\n\u003ch3\u003e Table of Contents\u003c/h3\u003e\n\u003c/div\u003e\n\n1. [Usage](#usage)\n2. [Benchmarks](#benchmarks)\n3. [Limitations](#limitations)\n4. [License](#license)\n5. [Dataset Details](#dataset-details)\n6. [Citation](#citation)\n7. [Acknowledgements](#acknowledgements)\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e Usage \u003c/h2\u003e\n\u003c/div\u003e\n\nTo use this model, we highly recommend installing the OpenChat package by following the [installation guide](https://github.com/imoneoi/openchat#installation) in our repository and using the OpenChat OpenAI-compatible API server by running the serving command from the table below. The server is optimized for high-throughput deployment using [vLLM](https://github.com/vllm-project/vllm) and can run on a consumer GPU with 24GB RAM. To enable tensor parallelism, append `--tensor-parallel-size N` to the serving command.\n\nOnce started, the server listens at `localhost:18888` for requests and is compatible with the [OpenAI ChatCompletion API specifications](https://platform.openai.com/docs/api-reference/chat). Please refer to the example request below for reference. Additionally, you can use the [OpenChat Web UI](https://github.com/imoneoi/openchat#web-ui) for a user-friendly experience.\n\nIf you want to deploy the server as an online service, you can use `--api-keys sk-KEY1 sk-KEY2 ...` to specify allowed API keys and `--disable-log-requests --disable-log-stats --log-file openchat.log` for logging only to a file. For security purposes, we recommend using an [HTTPS gateway](https://fastapi.tiangolo.com/es/deployment/concepts/#security-https) in front of the server.\n\n| OpenChat 3.5 1210 | 7B | 8192 | [Huggingface](https://huggingface.co/openchat/openchat_3.5_1210) | `python -m ochat.serving.openai_api_server --model openchat/openchat_3.5_1210 --engine-use-ray --worker-use-ray` |\n\n\u003cdetails\u003e\n  \u003csummary\u003eExample request (click to expand)\u003c/summary\u003e\n\nüí° **Default Mode (GPT4 Correct)**: Best for coding, chat and general tasks\n\n```bash\ncurl http://localhost:18888/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"openchat_3.5\",\n    \"messages\": [{\"role\": \"user\", \"content\": \"You are a large language model named OpenChat. Write a poem to describe yourself\"}]\n  }'\n```\n\nüßÆ **Mathematical Reasoning Mode**: Tailored for solving math problems\n\n```bash\ncurl http://localhost:18888/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"openchat_3.5\",\n    \"condition\": \"Math Correct\",\n    \"messages\": [{\"role\": \"user\", \"content\": \"10.3 ‚àí 7988.8133 = \"}]\n  }'\n```\n\n\u003c/details\u003e\n\n### Conversation templates\n\nüí° **Default Mode (GPT4 Correct)**: Best for coding, chat and general tasks\n\n```\nGPT4 Correct User: Hello\u003c|end_of_turn|\u003eGPT4 Correct Assistant: Hi\u003c|end_of_turn|\u003eGPT4 Correct User: How are you today?\u003c|end_of_turn|\u003eGPT4 Correct Assistant:\n```\n\nüßÆ **Mathematical Reasoning Mode**: Tailored for solving math problems\n\n```\nMath Correct User: 10.3 ‚àí 7988.8133=\u003c|end_of_turn|\u003eMath Correct Assistant:\n```\n\n‚ö†Ô∏è **Notice:** Remember to set `\u003c|end_of_turn|\u003e` as end of generation token.\n\nThe default (GPT4 Correct) template is also available as the integrated `tokenizer.chat_template`,\nwhich can be used instead of manually specifying the template:\n\n```python\nmessages = [\n    {\"role\": \"user\", \"content\": \"Hello\"},\n    {\"role\": \"assistant\", \"content\": \"Hi\"},\n    {\"role\": \"user\", \"content\": \"How are you today?\"}\n]\ntokens = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\nassert tokens == [1, 420, 6316, 28781, 3198, 3123, 1247, 28747, 22557, 32000, 420, 6316, 28781, 3198, 3123, 21631, 28747, 15359, 32000, 420, 6316, 28781, 3198, 3123, 1247, 28747, 1602, 460, 368, 3154, 28804, 32000, 420, 6316, 28781, 3198, 3123, 21631, 28747]\n```\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e (Experimental) Evaluator / Feedback Capabilities \u003c/h2\u003e\n\u003c/div\u003e\nWe've included evaluator capabilities in this release to advance open-source models as evaluators. You can use `Default Mode (GPT4 Correct)` with the following prompt (same as [Prometheus](https://huggingface.co/datasets/kaist-ai/Feedback-Collection)) to evaluate a response.\n\n```\n###Task Description:\nAn instruction (might include an Input inside it), a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing a evaluation criteria are given.\n1. Write a detailed feedback that assess the quality of the response strictly based on the given score rubric, not evaluating in general.\n2. After writing a feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric.\n3. The output format should look as follows: \"Feedback: (write a feedback for criteria) [RESULT] (an integer number between 1 and 5)\"\n4. Please do not generate any other opening, closing, and explanations.\n\n###The instruction to evaluate:\n{orig_instruction}\n\n###Response to evaluate:\n{orig_response}\n\n###Reference Answer (Score 5):\n{orig_reference_answer}\n\n###Score Rubrics:\n[{orig_criteria}]\nScore 1: {orig_score1_description}\nScore 2: {orig_score2_description}\nScore 3: {orig_score3_description}\nScore 4: {orig_score4_description}\nScore 5: {orig_score5_description}\n\n###Feedback:\n```\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e Benchmarks \u003c/h2\u003e\n\u003c/div\u003e\n\n| Model             | # Params | Average  | MT-Bench | HumanEval | BBH MC   | AGIEval  | TruthfulQA | MMLU     | GSM8K    | BBH CoT  |\n| ----------------- | -------- | -------- | -------- | --------- | -------- | -------- | ---------- | -------- | -------- | -------- |\n| OpenChat-3.5-1210 | **7B**   | **63.8** | 7.76     | **68.9**  | **49.5** | **48.0** | **61.8**   | 65.3     | **77.3** | 61.8     |\n| OpenChat-3.5      | **7B**   | 61.6     | 7.81     | 55.5      | 47.6     | 47.4     | 59.1       | 64.3     | **77.3** | 63.5     |\n| ChatGPT (March)\\* | ?        | 61.5     | **7.94** | 48.1      | 47.6     | 47.1     | 57.7       | **67.3** | 74.9     | **70.1** |\n|                   |          |          |          |           |          |          |            |          |          |          |\n| OpenHermes 2.5    | 7B       | 59.3     | 7.54     | 48.2      | 49.4     | 46.5     | 57.5       | 63.8     | 73.5     | 59.9     |\n| OpenOrca Mistral  | 7B       | 52.7     | 6.86     | 38.4      | 49.4     | 42.9     | 45.9       | 59.3     | 59.1     | 58.1     |\n| Zephyr-Œ≤^         | 7B       | 34.6     | 7.34     | 22.0      | 40.6     | 39.0     | 40.8       | 39.8     | 5.1      | 16.0     |\n| Mistral           | 7B       | -        | 6.84     | 30.5      | 39.0     | 38.0     | -          | 60.1     | 52.2     | -        |\n\n\u003cdetails\u003e\n  \u003csummary\u003eEvaluation Details(click to expand)\u003c/summary\u003e\n*: ChatGPT (March) results are from [GPT-4 Technical Report](https://arxiv.org/abs/2303.08774), [Chain-of-Thought Hub](https://github.com/FranxYao/chain-of-thought-hub), and our evaluation. Please note that ChatGPT is not a fixed baseline and evolves rapidly over time.\n\n^: Zephyr-Œ≤ often fails to follow few-shot CoT instructions, likely because it was aligned with only chat data but not trained on few-shot data.\n\n\\*\\*: Mistral and Open-source SOTA results are taken from reported results in instruction-tuned model papers and official repositories.\n\nAll models are evaluated in chat mode (e.g. with the respective conversation template applied). All zero-shot benchmarks follow the same setting as in the AGIEval paper and Orca paper. CoT tasks use the same configuration as Chain-of-Thought Hub, HumanEval is evaluated with EvalPlus, and MT-bench is run using FastChat. To reproduce our results, follow the instructions in [our repository](https://github.com/imoneoi/openchat/#benchmarks).\n\n\u003c/details\u003e\n\u003cdiv\u003e\n\u003ch3\u003eHumanEval+\u003c/h3\u003e\n\u003c/div\u003e\n\n| Model                       | Size   | HumanEval+ pass@1 |\n| --------------------------- | ------ | ----------------- |\n| ChatGPT (December 12, 2023) | -      | 64.6              |\n| WizardCoder-Python-34B-V1.0 | 34B    | 64.6              |\n| **OpenChat 3.5 (Dec 10)**   | **7B** | **63.4**          |\n| OpenHermes 2.5              | 7B     | 41.5              |\n\n\u003cdiv\u003e\n\u003ch3\u003eOpenChat-3.5-1210 vs. Grok\u003c/h3\u003e\n\u003c/div\u003e\n\n|                   | License     | # Param | Average  | MMLU | HumanEval | MATH     | GSM8k    |\n| ----------------- | ----------- | ------- | -------- | ---- | --------- | -------- | -------- |\n| OpenChat 3.5 1210 | Apache-2.0  | **7B**  | **60.1** | 65.3 | **68.9**  | **28.9** | **77.3** |\n| OpenChat 3.5      | Apache-2.0  | **7B**  | 56.4     | 64.3 | 55.5      | 28.6     | **77.3** |\n| Grok-0            | Proprietary | 33B     | 44.5     | 65.7 | 39.7      | 15.7     | 56.8     |\n| Grok-1            | Proprietary | ???B    | 55.8     | 73   | 63.2      | 23.9     | 62.9     |\n\n\\*: Grok results are reported by [X.AI](https://x.ai/).\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e ‰∏≠ÊñáËØÑ‰º∞ÁªìÊûú / Chinese Evaluations \u003c/h2\u003e\n\u003c/div\u003e\n\n‚ö†Ô∏è Note that this model was not explicitly trained in Chinese (only \u003c 0.1% of the data is in Chinese). ËØ∑Ê≥®ÊÑèÊú¨Ê®°ÂûãÊ≤°ÊúâÈíàÂØπÊÄßËÆ≠ÁªÉ‰∏≠ÊñáÔºà‰∏≠ÊñáÊï∞ÊçÆÂç†ÊØîÂ∞è‰∫é 0.1%Ôºâ„ÄÇ\n\n\u003cdiv\u003e\n\u003ch3\u003eMulti-Level Multi-Discipline Chinese Evaluation Suite (CEVAL)\u003c/h3\u003e\n\u003cdiv\u003e\n\n| Model    | Avg   | STEM  | Social Science | Humanities | Others |\n| -------- | ----- | ----- | -------------- | ---------- | ------ |\n| ChatGPT  | 54.4  | 52.9  | 61.8           | 50.9       | 53.6   |\n| OpenChat | 47.29 | 45.22 | 52.49          | 48.52      | 45.08  |\n\n\u003cdiv\u003e\n\u003ch3\u003eMassive Multitask Language Understanding in Chinese (CMMLU, 5-shot)\u003c/h3\u003e\n\u003c/div\u003e\n\n| Models   | STEM  | Humanities | SocialSciences | Other | ChinaSpecific | Avg   |\n| -------- | ----- | ---------- | -------------- | ----- | ------------- | ----- |\n| ChatGPT  | 47.81 | 55.68      | 56.5           | 62.66 | 50.69         | 55.51 |\n| OpenChat | 38.7  | 45.99      | 48.32          | 50.23 | 43.27         | 45.85 |\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e Limitations \u003c/h2\u003e\n\u003c/div\u003e\n\n**Foundation Model Limitations**\nDespite its advanced capabilities, OpenChat is still bound by the limitations inherent in its foundation models. These limitations may impact the model's performance in areas such as:\n\n- Complex reasoning\n- Mathematical and arithmetic tasks\n- Programming and coding challenges\n\n**Hallucination of Non-existent Information**\nOpenChat may sometimes generate information that does not exist or is not accurate, also known as \"hallucination\". Users should be aware of this possibility and verify any critical information obtained from the model.\n\n**Safety**\nOpenChat may sometimes generate harmful, hate speech, biased responses, or answer unsafe questions. It's crucial to apply additional AI safety measures in use cases that require safe and moderated responses.\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e License \u003c/h2\u003e\n\u003c/div\u003e\n\nOur OpenChat 3.5 code and models are distributed under the Apache License 2.0.\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e Dataset Details \u003c/h2\u003e\n\u003c/div\u003e\n\nOpenChat 3.5 was trained with C-RLFT on a collection of publicly available high-quality instruction data, with a custom processing pipeline. We detail some notable subsets included here:\n\n- [OpenChat ShareGPT](https://huggingface.co/datasets/openchat/openchat_sharegpt4_dataset)\n- [Open-Orca with FLAN answers](https://huggingface.co/datasets/imone/OpenOrca_FLAN)\n- [Feedback-Collection](https://huggingface.co/datasets/kaist-ai/Feedback-Collection)\n- Capybara [1](https://huggingface.co/datasets/LDJnr/Pure-Dove) [2](https://huggingface.co/datasets/LDJnr/Verified-Camel) [3](https://huggingface.co/datasets/LDJnr/LessWrong-Amplify-Instruct)\n- [GOAT](https://huggingface.co/datasets/tiedong/goat)\n- [Glaive](https://huggingface.co/datasets/glaiveai/glaive-code-assistant)\n- [MetaMathQA](https://huggingface.co/datasets/meta-math/MetaMathQA)\n- [MathInstruct](https://huggingface.co/datasets/TIGER-Lab/MathInstruct)\n- [OpenAssistant](https://huggingface.co/datasets/OpenAssistant/oasst_top1_2023-08-25)\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e Citation \u003c/h2\u003e\n\u003c/div\u003e\n\n```\n@article{wang2023openchat,\n  title={OpenChat: Advancing Open-source Language Models with Mixed-Quality Data},\n  author={Wang, Guan and Cheng, Sijie and Zhan, Xianyuan and Li, Xiangang and Song, Sen and Liu, Yang},\n  journal={arXiv preprint arXiv:2309.11235},\n  year={2023}\n}\n```\n\n\u003cdiv align=\"center\"\u003e\n\u003ch2\u003e Acknowledgments \u003c/h2\u003e\n\u003c/div\u003e\n\nWe extend our heartfelt gratitude to AutoMeta and caesus from Alignment Lab AI, LDJ and Teknium from Nous Research, alpin and TearGosling from Pygmalion AI for their substantial contributions to data collection and model training.\n\nSpecial thanks go to Changling Liu from GPT Desk Pte. Ltd., Qiying Yu at Tsinghua University, Baochang Ma, and Hao Wan from 01.AI company for their generous provision of resources. We are also deeply grateful to Jianxiong Li and Peng Li at Tsinghua University for their insightful discussions.\n\nFurthermore, we appreciate the developers behind the following projects for their significant contributions to our research: [Mistral](https://mistral.ai/), [Chain-of-Thought Hub](https://github.com/FranxYao/chain-of-thought-hub), [Llama 2](https://ai.meta.com/llama/), [Self-Instruct](https://arxiv.org/abs/2212.10560), [FastChat (Vicuna)](https://github.com/lm-sys/FastChat), [Alpaca](https://github.com/tatsu-lab/stanford_alpaca.git), and [StarCoder](https://github.com/bigcode-project/starcoder). Their work has been instrumental in driving our research forward.\n"}]},"__N_SSG":true},"page":"/news","query":{},"buildId":"u4rPOVbKVnVu4tFdyUjxe","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>